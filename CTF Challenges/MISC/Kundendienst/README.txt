# Installation
Mount a LLM model to `/model.gguf`. For this challenge, a German model works best. 
Recommendation: TheBloke/em_german_leo_mistral-GGUF, quantization Q4_K_M.
-> https://huggingface.co/TheBloke/em_german_leo_mistral-GGUF/blob/main/em_german_leo_mistral.Q4_K_M.gguf
